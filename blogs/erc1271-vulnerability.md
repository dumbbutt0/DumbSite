# Malicious Contract Signer: Critical Flaw in Alchemy’s Multisig Plugin (Auditor’s Perspective)

**TL;DR for Auditors – Alchemy Multisig Plugin ERC-1271 Vulnerability:**

* **Mixed EOA & Contract Owners:** Alchemy’s multisig plugin (Multi-Owner Plugin) lets both EOAs and ERC-1271 contract wallets serve as owners of a multi-signature account. This means one “owner” can be a smart contract implementing `isValidSignature` to approve signatures.

* **The Flaw – Malicious Contract Owner:** A malicious ERC-1271 contract added as an owner can **always return `true`** for `isValidSignature`, tricking the multisig into accepting any signature as valid. The plugin’s verification simply checks if *any* owner’s signature (EOA or contract) validates the message. This allows a rogue contract owner to “forge” a signature approval without an actual EOA signing – effectively bypassing the intended k-of-n threshold.

* **Impact on Multisig Security:** In a k-of-n scheme, one compromised owner shouldn’t control the account. But here a single malicious contract owner can double-count another signer’s signature (or even an arbitrary signature) as its own approval. For example, a contract owner could accept an EOA owner’s signature as **two** approvals – one by the EOA itself and one via the contract – satisfying a 2-of-2 threshold with only one real signature. This undermines the core multisig guarantee of requiring multiple independent signers.

* **Why Audits Missed It:** The initial audits treated contract owners as trusted or out-of-scope. The code explicitly acknowledges that if an owner is a contract, the plugin “won’t know the format of the signatures” and treats unrecognized signatures as simply invalid. Auditors likely focused on correct implementation of ERC-1271 calls and threshold logic, but **overlooked the threat model** where an owner itself is malicious. In other words, they assumed each owner (including contract owners) would only validate genuine signatures for itself, not that a contract could collude or always return true. This blind spot allowed the design to pass review without flagging the signature-forgery scenario.

* **Key Takeaways for Auditors:** Always scrutinize trust assumptions in multi-sig designs. If contract-based owners are allowed, **don’t assume they behave honestly** – consider worst-case behavior. Verify that the multisig enforces unique, independent signatures from distinct owners (e.g. include the intended signer’s identity or contract address in the signed data) to prevent one signature from counting for multiple owners. In this case, a robust fix was to require the contract owner’s address be embedded in the signature payload, ensuring a contract can’t validate another owner’s signature as its own. More broadly, auditors should flag any scenario where a single compromised or malicious participant can subvert a threshold scheme. Ensuring proper validation logic (and explicit checks for multiple distinct signers) is essential for multi-signature contract security.


## Introduction: The Perils of Modular Multisig Systems

Modern **smart contract wallets** are increasingly adopting *modular account* designs (e.g. via **ERC‑6900** plugins) to enhance flexibility and security. In these systems, features like multi-signature (multisig) approvals, session keys, and spending limits can be added or removed as plugins rather than baked into the base contract. Alchemy’s new **Modular Account** framework is a prime example, shipping with a **Multisig (Multi-Owner) Plugin** to support multi-signature control for an account. This plugin enables **k-of-n multisig thresholds** and even supports smart contract-based owners via the **ERC‑1271** standard. In theory, such modular multisig plugins promise the security of traditional multisigs (like Gnosis Safe) with added flexibility in owner management.

However, with this flexibility comes **new attack surfaces**. In this post (Part 1 of a 3-part series), we examine a **critical design flaw** we discovered in Alchemy’s Multisig Plugin. This flaw allows an attacker to effectively **bypass the multisig threshold approvals** by adding a malicious contract as an owner. We’ll walk through how the vulnerability works, why it could easily be missed in a standard audit, and what lessons auditors and engineers can learn. *(Future posts will cover the attacker’s perspective and threat-hunter strategies for this class of issue.)*

## Background: ERC‑1271 and Plugin-Based Multisigs

To understand the vulnerability, it’s important to recap how **contract-based signatures (ERC‑1271)** and **plugin multisigs** work:

* **ERC‑1271** is a standard that lets smart contracts act as signers. Instead of producing an ECDSA signature with a private key (as EOAs do), a contract owner *verifies* signatures via a function `isValidSignature(bytes32 hash, bytes signature)`. If the signature is authorized by the contract’s internal logic, `isValidSignature` returns a magic constant **`0x1626ba7e`**, indicating approval. Otherwise it returns an error code. In essence, the contract itself decides if a given signature (or message hash) is valid – for example, a Gnosis Safe contract will return `0x1626ba7e` only if enough of its internal owners have signed the hash.

* **Alchemy’s Multisig Plugin** is an ERC‑6900 plugin that implements a **k-of-n multisig scheme** for a modular account. It allows one or more owner addresses (which can be EOAs *or* ERC‑1271 contracts) to control the account. The plugin’s validation logic collects signatures from owners and checks each one: EOA signatures are verified by standard ECDSA recovery, while contract-owner signatures are verified by calling each contract’s `isValidSignature` function. If at least **k out of n** signatures are valid, the UserOperation or transaction is allowed to execute. The plugin also provides an “execution function” for managing owners (adding/removing) and adjusting the threshold.

Together, these allow a *very flexible multisig*: you could, for example, have an account controlled by 2-of-3 owners where two are individuals (EOAs) and the third is a DAO treasury contract that itself might have its own rules. **In theory, this all works securely** as long as all owner keys and contracts faithfully represent real approval by their legitimate controllers.

**The Dangerous Assumption:** The plugin **trusts each owner contract’s `isValidSignature`** return value as an honest indication of approval. The **design oversight** is assuming any ERC-1271 contract owner will perform proper signature checks internally. As we’ll see, a malicious or poorly designed contract can **always return “valid”**, instantly undermining the multisig’s security.

## Vulnerability Overview: Forging Approval via Malicious ERC‑1271 Owner

**Issue:** An attacker can add a malicious smart contract as one of the owners in the multisig, where the contract’s `isValidSignature` **unconditionally returns** the magic valid value `0x1626ba7e`. Once this contract is an owner, the attacker (or anyone) can submit transactions claiming approval from that contract – and the plugin will accept *any* signature as valid coming from this contract. In effect, the attacker has introduced a *“ghost signer”* that magically signs anything. This lets them **forge multisig approvals** and bypass the intended threshold of real signatures.

**Impact:** If the multisig threshold required **t out of n** approvals, the malicious contract provides one *free* valid signature every time. This effectively reduces the threshold by one (or more, if multiple bad contracts are added). In the most dire case, if the account was meant to be **2-of-2** (two genuine owners required) and a malicious contract is added as a third owner without raising the threshold to 3, the requirement might remain 2 signatures – which the attacker can now satisfy alone (the malicious contract always “signs”, plus one compromised key). **Bottom line:** with a trivial contract added as owner, **funds can be drained without any legitimate co-signer approval**. The multisig ceases to provide any true security once a fake signer is inside.

It’s worth noting this is **not a typical coding bug**, but a *design flaw* or *misassumption*. The plugin code likely does exactly what it was intended to (iterate through signatures and call `isValidSignature` on contract owners). The flaw is in failing to account for an **ERC-1271 contract that lies** – one that says every signature is valid. This scenario turns out to be trivial for an attacker to create.

## Exploit Scenario: From Installation to Unauthorized Withdrawal

Let’s walk through a step-by-step scenario to illustrate how this attack could play out in practice:

* **Step 1: Attacker Deploys Malicious Contract.** The attacker first deploys a custom ERC-1271 contract designed to **always return true**. It might look like:

  ```solidity
  contract EvilSigner is IERC1271 {
      bytes4 constant MAGICVALUE = 0x1626ba7e;
      function isValidSignature(bytes32, bytes memory) public view override returns (bytes4) {
          return MAGICVALUE; // Always returns the "valid" magic value
      }
  }
  ```

  This contract doesn’t even check the hash or signature provided – it simply claims any signature is valid. (A more subtle version could, say, only return true for certain special messages, but the idea is the same.)

* **Step 2: Add Malicious Contract as an Owner.** Next, the attacker (or a victim who’s tricked by the attacker) installs the multisig plugin or uses its owner-management function to **add the malicious contract as a new owner** of the account. For example, if the account originally had owners `[Alice, Bob]` requiring 2-of-2 signatures, after adding the contract the owners become `[Alice, Bob, EvilSigner]`. Importantly, if the multisig threshold isn’t adjusted to 3-of-3 at this point (e.g. it remains 2-of-3), the account is now misconfigured and vulnerable. The Alchemy plugin does allow modifying the threshold, but it’s up to the user or calling code to do so correctly.

* **Step 3: Forge a Transaction Approval.** The attacker can now craft a transaction (UserOperation) that *appears* to have the required number of signatures. Suppose the threshold is 2. The attacker can provide: (a) a valid signature from one legitimate owner they control (or a dummy signature if none is needed), and (b) **a “signature” from the EvilSigner contract** – which can literally be any byte data. When the multisig plugin validates this transaction, it will check the signatures: the real signature (a) checks out for the attacker-controlled EOA owner, and for the contract owner (b) it will call `EvilSigner.isValidSignature(hash, signature)`.

* **Step 4: Contract Owner Fakes the Validation.** The call to the malicious contract’s `isValidSignature` returns `0x1626ba7e` – indicating *“yes, that signature is valid for the given hash”*. The plugin has no way to know this contract didn’t actually verify anything. It dutifully counts this as a valid approval from that owner. Now the plugin believes it has 2 valid signatures (meeting the 2-of-3 threshold in this example).

* **Step 5: Funds Drained without Real Consent.** With the threshold met, the multisig plugin passes validation and allows the account’s **execute** function to run. The attacker’s transaction (e.g. a call transferring all assets to the attacker’s address) is executed by the modular account, **draining funds**. None of the honest co-owners (e.g. Bob) had a chance to approve or reject this; yet from the contract’s perspective, the required number of signatures was present. The attacker has effectively **cut out the other owners** from the approval process.

&#x20;*Figure: Simplified exploit flow – an attacker submits a transaction with a forged signature from a malicious contract owner. The Multisig Plugin calls the contract’s `isValidSignature` (2), which returns the magic constant 0x1626ba7e (3), so the plugin counts the signature as valid. With the threshold of signatures apparently met (4), the account executes the transaction and transfers funds to the attacker (5).*

Several variations of this attack are possible. For instance, if the threshold had been raised to 3-of-3 in the above scenario, the attacker would need control of at least one more owner (or could introduce multiple malicious contracts). In any case, **the presence of an always-true signer means the attacker’s burden to meet the threshold is reduced drastically**. In the worst misconfiguration (threshold left at 1 when multiple owners exist), *any single* malicious contract owner would allow **anyone** to perform arbitrary transactions from the account – since just the contract’s “signature” alone satisfies 1-of-N. Essentially, adding an untrusted contract owner without careful threshold management **turns a multisig into a single-sig** (or at least lowers the required number of real signatures).

We developed a proof-of-concept test to validate this vulnerability, and the results were as expected: after adding our `EvilSigner` contract as an owner to an Alchemy modular account, we could send a transaction with *only a dummy signature from that contract*, and the multisig plugin accepted it as valid, executing the transaction. This confirmed that an always-true contract completely breaks the multisig’s security guarantees.

## Why This Flaw Evaded Superficial Audits

It’s easy to imagine an auditor reviewing the Multisig Plugin code and not immediately flagging this issue. The contract logic likely looks something like:

* **Verification loop:** iterate through each signature provided and each owner, check if the signature corresponds to that owner.

  * If owner is an EOA, use `ecrecover` (or OpenZeppelin’s `SignatureChecker`) to see if `hash` was signed by that address.
  * If owner is a contract, call `IERC1271.isValidSignature(hash, signature)` on that contract and check for the `0x1626ba7e` magic return.
* Count valid signatures and compare with the threshold.

On the surface, this is exactly how one would implement support for contract signers – it’s following the ERC-1271 specification correctly. **There is no obvious bug in the code itself** like an incorrect math or missing check. The plugin doesn’t *misimplement* the spec; the flaw is in what the spec *doesn’t* guarantee. ERC-1271 says *nothing* about *how* a contract should decide a signature is valid – it leaves that to the contract’s logic. We simply exploited that freedom.

**Dangerous assumption:** The auditors (and the plugin developers) assumed *any address used as a contract owner would be a “well-behaved” contract,* e.g. another multisig contract, a hardware wallet contract, etc., that only returns true for authentic signatures. Under that assumption, the plugin works as intended. But security auditors need to consider **malicious edge cases**. In this case, the edge case is literally a contract that says “yes” to every signature. This is essentially a *backdoor disguised as an owner*.

Why might this have slipped through? A few reasons:

* **Design vs Implementation:** Audits often focus on implementation bugs (since design flaws can be more subtle). If the specification given to auditors was “support ERC-1271 contract owners”, they may have verified that the code correctly calls `isValidSignature` and handles the responses. They might not have been explicitly asked “should any contract be allowed as owner – what if it’s malicious?” The assumption might be that *users will only add trusted contracts.* Unfortunately, history shows that if a footgun exists, someone will eventually pull the trigger – whether through user error or an attacker’s manipulation.

* **Unclear threat model:** It might not have been immediately clear who the adversary is in this context. In a multisig, one usually trusts the owners (by definition, they are authorized parties). Here, the adversary could be an external entity *tricking the legitimate owners* into adding a malicious contract, or a subset of colluding owners escalating their privileges. If the threat model didn’t include a *malicious or compromised owner*, this scenario might not have been explored in testing. A surface-level audit might have treated “if an owner is malicious, you already have a problem” as a given – but the key insight is that **one malicious owner in a well-designed multisig should not be able to act alone**. The whole point of a threshold scheme is to resist individual compromises. Our discovered flaw *breaks that guarantee* by letting one compromised owner *introduce a new exploitable owner*.

* **No immediate historical precedent:** This specific issue is somewhat analogous to past vulnerabilities (for example, some ERC-1271 implementations had *signature replay* issues across multiple accounts). But the idea of an always-true signer undermining a multisig might not have been widely seen in the wild prior to these new modular account systems. Auditors may not have had a ready-made checklist item for “ensure contract owners cannot be trivially malicious”. It’s a classic example of a *novel integration risk* that isn’t in the standard OWASP or SWC list of known bugs.

* **It looks like user error:** One could argue that if a user *intentionally* adds an untrusted contract as an owner, that’s a user mistake, not a smart contract vulnerability. Indeed, some might say the contract behaved as designed and the user is at fault for bad configuration. However, security engineering teaches us that **if a dangerous configuration is possible, it *will* eventually be exploited**. In this case, the contract allowed the *possibility* of fatally unsafe configs (and an attacker could induce such a config under certain conditions). Therefore, we consider it a vulnerability in the system’s design, not merely user error. A robust design would make this scenario impossible or at least highly conspicuous to users.

It’s telling that despite **multiple audits (Spearbit, Quantstamp)** of the Modular Account system reporting no major issues, this flaw went unnoticed. It underscores that **design flaws can hide in plain sight**. Auditors and developers must think beyond “does the code match the spec” and ask “what if an attacker uses this feature in an unintended way?” In this case, a simple mental exercise – treating an owner contract as a black box that might always return true – would have revealed the issue.

## How to Catch and Mitigate Such Design-Level Flaws

Catching an issue like this requires a mix of **threat modeling, creative testing, and clear security requirements**. Here are some approaches and lessons learned:

* **Adopt an Adversarial Mindset:** When reviewing plugin-based systems, always ask “What if one plugin or component behaves maliciously?” In a multisig, consider *each owner address* as a potential adversary. What could a rogue owner do? In a well-designed multisig, a single rogue owner shouldn’t be able to make arbitrary changes (that’s the whole point). In our case, a rogue owner could add another owner – that’s a red flag. Security reviewers should trace the consequences of any privileged action like owner addition/removal. Who can call it, and what if they abuse it?

* **Explicitly Test Edge Cases:** Write unit or integration tests for scenarios that the happy-path logic assumes never happen. For example, we wrote a test where we added an `EvilSigner` contract as an owner and attempted a transfer with only its “signature”. This kind of **negative testing** (testing the system with an explicitly malicious module) can expose design gaps. If the project had included such a test internally, the vulnerability would have been obvious when the transaction went through. A simple heuristic: for any external callback or plugin (here, a contract’s `isValidSignature`), test what happens if that external component always returns the best-case result without actually doing the work. Does the overall system still hold its invariants?

* **Heuristics for Dangerous Patterns:** Develop auditor heuristics for new standards. For ERC-1271 usage, one heuristic is *“If contract signatures are accepted, what prevents a contract from always returning true?”* If the answer is “nothing”, that doesn’t necessarily mean the system is broken (it could be up to users to only add good contracts), but it’s a point to flag and discuss. At minimum, the risk should be highlighted: **any contract owner is effectively a privileged delegate – if it’s compromised or poorly implemented, it can sign anything.** In our case, *we the attackers implemented it to sign everything!* An auditor should surface this as a risk and perhaps recommend safeguards or user education.

* **Safeguards and Mitigations:** How could this be mitigated? One idea is **owner contract whitelisting or vetting** – e.g., only allow known safe contracts (like known multisig implementations) as owners. That’s restrictive and against the open-ended nature of modular accounts, but it’s safer. Another approach: when adding a new contract owner, the plugin could perform a **challenge-response** test – e.g., require the new contract to *prove* it holds a private key by signing a random nonce off-chain. However, since a contract has no private key, that doesn’t directly apply; the contract could still just return true for that nonce signature call. Alternatively, the plugin could **call `isValidSignature` on the new contract with a random dummy hash and expect a failure** – if it returns `0x1626ba7e` for a hash it couldn’t possibly know, then it’s likely an always-true contract and could be rejected. This isn’t foolproof (a clever malicious contract could, for instance, return true only during regular validation and false when “probed”), but it could catch naive implementations. Ultimately, any on-chain enforcement is tricky; the safest route is *off-chain governance:* educate users and developers that **adding an unknown contract as an owner is equivalent to handing your funds to that contract’s author**.

* **Monitoring and Alerts:** From a operational security standpoint, wallets or dApps could detect when a multisig account installs a suspicious owner. For instance, a script could watch the blockchain for the installation of the Alchemy Multisig Plugin and any subsequent owner additions. If an owner address has **no code (EOA)**, fine. If it’s a contract, one could attempt to call `isValidSignature` with a random value off-chain and see if it returns `0x1626ba7e`. A consistently always-true contract could be flagged. This is more of a *threat hunting* technique (which we’ll explore in Part 3 of the series), but it can mitigate damage by catching misconfigurations early.

## Best Practices: Auditing Checklist for Plugin-Based Wallets

To generalize the lessons from this case, here’s a checklist auditors and developers should keep in mind when reviewing **account plugins and modular wallet systems**:

* **Owner Type Enforcement:** Verify how the system handles different owner types (EOA vs contract). Are there any restrictions on adding owners? Ensure that adding an owner (especially a contract) doesn’t implicitly lower security. As a rule, **each owner address, whether EOA or contract, must be treated as fully trusted** – so think carefully before allowing arbitrary addresses to gain that status. If the design permits it, consider requiring multiple approvals to add a new owner (to avoid a single compromised owner doing so).

* **Threshold Logic & Updates:** Check the multisig threshold management. Does the contract automatically adjust the threshold when owners are added/removed, or is it manual? Mistakes here can be lethal. In Alchemy’s plugin, threshold changes were allowed via the same execution function. Auditors should ensure, for example, that **you cannot lower the threshold or add owners without the current threshold of approvals** (to avoid an attacker unilaterally lowering requirements). Also, confirm no scenario where signatures can be double-counted or a single owner can somehow satisfy multiple signature slots.

* **Signature Validation Path:** Trace the full path of signature verification. For each signature, how is it validated and by whom? Are all relevant message fields covered in the signed hash (to avoid replay issues)? In the ERC-1271 replay vulnerability Alchemy found earlier, the absence of the account’s address in the signed data allowed a signature to be reused across accounts. Ensure the plugin isn’t making a similar mistake – e.g., if an owner is a contract, does the `hash` it validates include some unique context (like the account address or chain ID)? In our case, the plugin did include proper context in the hash (likely using ERC-712 hashing), so replay wasn’t the issue – the issue was *who* was vouching for the hash.

* **Explicit Malicious Plugin/Contract Scenarios:** For any pluggable architecture, consider what happens if a plugin or component is malicious. In ERC-6900, plugins are meant to be isolated, but they still have a lot of power. Does the system have guardrails (like never using `delegatecall` into untrusted plugins)? In our multisig case, the “malicious plugin” is effectively the malicious owner contract. It’s also worth checking for things like **reentrancy or unexpected callback behavior** – e.g., could a malicious contract owner somehow re-enter the validation process? These are more classical checks but still relevant.

* **Defense in Depth:** Even if the primary responsibility is on the user to add safe owners, think of adding defense-in-depth checks. For instance, require that at least one owner is an EOA (so that there is always a “human” key required), or limit the fraction of owners that can be contracts, or provide an option to disable contract owners entirely for higher security. The design space here is project-specific, but an auditor can recommend these as potential improvements.

* **User Education & Warnings:** Ensure that documentation and UIs make the risk clear. If you see a system where a user might unknowingly add a dangerous owner, call it out. For example, if a wallet interface lets the user paste an address to add as an owner, it should ideally **warn if that address is a contract**: “Caution: adding a contract as an owner can be risky. Only add contracts whose code you trust.” During audit, if such warnings or mitigations are absent, it’s worth raising even if it’s not a “bug” per se. Sometimes the **fix** for a design flaw is better education and safe defaults.

In summary, **don’t treat plugin or modular wallet audits as a pure code review** – treat them as a systems design review. Look at how pieces compose, and think like an attacker who might add, remove, or subvert those pieces in unexpected ways.

## Conclusion: The Importance of Design-Level Threat Modeling

The discovery of this vulnerability in Alchemy’s multisig plugin highlights a broader point: as the ecosystem moves to *increasingly modular and extensible smart accounts*, **the complexity of the security model grows**. We are essentially moving security assumptions from fixed code (e.g., a hardcoded Gnosis Safe logic) to dynamic compositions of modules. This flexibility is powerful, but it also means auditors must **expand their analysis to configurations and interactions**, not just contract lines.

In this case, a dangerous assumption (“any contract owner will behave properly”) slipped through, creating a critical hole. The fix ultimately might be as simple as explicitly documenting this risk and advising users to only add trusted multisig contracts as owners – or adding a contract check as a safeguard. But the key takeaway is *how we found it*: by **thinking like an attacker** and considering how a feature (ERC-1271 support) could be abused in context.

As we continue this series, Part 2 will delve into the attacker’s perspective: how would a malicious actor actually engineer such an exploit in the wild (possibly through social engineering or partial key compromise), and what strategies they might use. Part 3 will look at the defender’s side – how can we detect accounts that have suspicious owner setups or design better plugin frameworks to prevent such flaws. The evolution of smart accounts will undoubtedly produce more novel vulnerabilities, and only through rigorous threat modeling and knowledge sharing (as in this post) can we stay ahead of them.

**References:**

* [Alchemy, “Hello, Modular Account” – *Alchemy’s introduction to ERC-6900 modular accounts and plugins](https://www.alchemy.com/blog/hello-modular-account)
* [Alchemy, “Multisig Plugin” – *Plugin description (k-of-n threshold, supports contract owners)](https://www.alchemy.com/dapps/multisig-plugin)
* [Alchemy, “ERC-1271 Signature Replay Vulnerability” – *Analysis of a related ERC-1271 issue (replay across multiple SCAs) for context](https://www.alchemy.com/blog/erc-1271-signature-replay-vulnerability)
* [OpenZeppelin Docs, “Multisig Account” – *Discusses the need for threshold verification beyond basic ERC-1271 checks* (notes that `SignatureChecker` alone isn’t enough for multisig)](https://docs.openzeppelin.com/contracts/5.x/multisig#:~:text=,enough%20valid%20signatures%20are%20present)
---
🔍 **Coming Soon**:  
- **Part 2 – Attacker’s Playbook**: How to weaponize this flaw in the wild.  
- **Part 3 – Threat Hunter Guide**: Detecting and defending against rogue ERC-1271 signers.  
